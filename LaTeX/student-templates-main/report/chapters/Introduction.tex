%_________Einleitung__________________________________
\chapter{Introduction}
\label{sec:introduction}

Your first chapter in the document.
Introduce the problem (gently!). Try to give the reader an appreciation of the difficulty, and an idea of how you will go about it. It is like the overture of an opera: it plays on all the relevant themes.

In this chapter, the problem is introduced in Sec. \ref{Problem Statement} and some 

\section{Problem Statement} \label{Problem Statement}

Consider the general nonlinear discrete-time system of the form

\begin{subequations} \label{System equation}
\begin{equation}
\boldsymbol{x}_{t+1} = \boldsymbol{f} \left( \boldsymbol{x}_{t}, \boldsymbol{u}_t \right) + \boldsymbol{v}_{t}
\end{equation}
\begin{equation}
\boldsymbol{y}_{t} = \boldsymbol{g} \left( \boldsymbol{x}_{t}, \boldsymbol{u}_t \right) + \boldsymbol{w}_{t}
\end{equation}
\end{subequations}

with the state $\boldsymbol{x} \in \mathbb{R}^{n_x \in \mathbb{N}}$, the input $\boldsymbol{u} \in \mathbb{R}^{n_u \in \mathbb{N}}$, the output $\boldsymbol{y} \in \mathbb{R}^{n_y \in \mathbb{N}}$, the process noise $\boldsymbol{v}_{t} \in \mathbb{R}^{n_x}$, the measurement noise $\boldsymbol{w}_{t} \in \mathbb{R}^{n_y}$ and time $t \in \mathbb{Z}$. 

In our setting, only the output $\boldsymbol{y}$ is observable and the state transition function $\boldsymbol{f}(\cdot)$ and the observation function $\boldsymbol{g}(\cdot)$, as well as the distributions $\boldsymbol{\mathcal{V}}$ and $\boldsymbol{\mathcal{W}}$ of the process noise $\boldsymbol{v}$ and measurement noise $\boldsymbol{w}$ are unknown.

We assume that a dataset $\mathbb{D} = \left\{\boldsymbol{u}_{t}, \boldsymbol{y}_{t}\right\}_{t = \text{-}T:\text{-}1}$ containing the last $T \in \mathbb{N}$ measurements of the input $\boldsymbol{u}$ and output $\boldsymbol{y}$ is available.

We further assume that the structure of the model $\left\{\boldsymbol{f}_{\boldsymbol{\theta}}(\cdot), \boldsymbol{g}_{\boldsymbol{\theta}}(\cdot), \boldsymbol{\mathcal{V}}_{\boldsymbol{\theta}}, \boldsymbol{\mathcal{W}}_{\boldsymbol{\theta}}\right\}$ is known and is dependent on a finite number of unknown parameters $\boldsymbol{\theta}$. In addition to that, the priors $p(\boldsymbol{\theta})$ and $p(\boldsymbol{x}_{\text{-}T})$ are available as well.

The objective is to minimize a given cost function 

\begin{equation} \label{cost function}
J_H = \sum_{t = 0}^H c(\boldsymbol{u}_t,  \boldsymbol{x}_t,  \boldsymbol{y}_t)
\end{equation}

over the horizon $H$ while satisfying the constraints 

\begin{equation} \label{constraints}
\boldsymbol{h}(\boldsymbol{u}_{0:H},  \boldsymbol{x}_{0:H},  \boldsymbol{y}_{0:H}) \leq \boldsymbol{0}
\end{equation}

with $\boldsymbol{h} \in \mathbb{R}^{n_c}$ being a vector of arbitrary deterministic function. As the states $\boldsymbol{x}_{0:H}$ are unknown to us and there are several uncertain factors in our system, the constraints are transformed into chance-constraints and since it is possible that $\boldsymbol{h}$ is impossible to satisfy for every possible $\boldsymbol{x}_{0:H}$, we also introduce a risk factor $\alpha \in [0, 1]$ that relaxes these constraints, turning them into

\begin{equation} \label{risk constraints}
P \left[ h_i(\boldsymbol{u}_{0:H},  \boldsymbol{x}_{0:H},  \boldsymbol{y}_{0:H}) \leq 0 \right] \geq 1 - \alpha, \; \forall i = 1,...,n_c
\end{equation}

with $h_i$ being the $i$-th element of $\boldsymbol{h}$ and $P$ being generally unknown.

\section{Related Work}

%From Robert's \emph{Learning-Based Optimal Control with Performance Guarantees for Unknown Systems with Latent States}\cite{Robert2024}:

The problem presented in Sec. \ref{Problem Statement} provides several challenges as the information we have available is very limited. While many methods to solve chance constraint problems exist, they often rely on samples from the distribution $P$ which is generally unknown in our problem. While we do have priors for the uncertain elements, samples drawn from this distributions do not allow as to quantify the system enough for practical applications. As such, the priors must be updated based on the input-output measurements $\mathbb{D}$ which generally results in an analytically intractable posterior distribution.

To draw samples from this distribution, methods such as particle Markov chain Monte Carlo Methods \cite{Andrieu_10} can be used. This has recently been exploited for optimal control in \cite{Robert_24} , utilizing such a sampler to generate scenarios for the system and using these scenarios as a representation of the unknown distribution to formulate a deterministic optimal control problem by reformulating the chance-constraints. However, the usage of the scenarios in this paper comes with the drawback of the risk factor $\alpha$ not being part of the final optimal control problem (OCP) and the process of estimating it retroactively being quite ressource intensive.

As such, there is a need to find other methods that allow us to utilize the samples generated by PG sampler to reformulate the chance-constraints to find a distributionally robust solution without losing the risk factor in the process. As the difficulties with this can be traced back to the unknown distribution $P$, ambiguity sets have been proposed as a possible workaround. Here, ambiguity sets are defined as a set of probability distributions that are within a certain radius under an appropriate distance function. This was used in \cite{Hota_19} with Wasserstein distance as the metric for the ambiguity set. It has however been proven rather difficult to efficiently construct a Wasserstein ambiguity set for problems. 

In contrast, the metric proposed in \cite{Yassine_22} allows for an efficient construction of an ambiguity set using a maximum mean discrepancy (MMD) metric combined with kernel approximation and can be applied to gneral non-linear and non-convex constraints.

The remainder of this paper is structured as follows. In chapter \ref{Technical Approach}, we review the methods used to solve the OCP. These methods are then tested and evaluated in chapter \ref{Evaluation} and further discussed in chapter \ref{Discussion}. Finally, the results are summarized and some concluding remarks are given in chapter \ref{Conclusion}.



%____________________________________________________