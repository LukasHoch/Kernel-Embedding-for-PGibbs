%_________Einleitung__________________________________
\chapter{Introduction}
\label{sec:introduction}

Reliable mathmatical models are a fundamental component of any model-based control application. However, finding such a model is often very difficult as there are many considerations that go into creating or estimating it, with even small deviations sometimes leading to big differences. Oftentimes, it is impossible to create such a model only based on the general knowledge of the system, such as the physics of the application. Because of this, data-driven modeling approaches that allow for derive such models based on previously collected data are gaining attention and their usefulness for optimal control applications is being explored.

In this chapter, the problem is introduced in Sec. \ref{Problem Statement} and various works that are connected to this topic are shown and summarized in \ref{Related Work}.

\section{Problem Statement} \label{Problem Statement}

Consider the general nonlinear discrete-time system of the form

\begin{subequations} \label{System equation}
\begin{equation}
\boldsymbol{x}_{t+1} = \boldsymbol{f} \left( \boldsymbol{x}_{t}, \boldsymbol{u}_t \right) + \boldsymbol{v}_{t}
\end{equation}
\begin{equation}
\boldsymbol{y}_{t} = \boldsymbol{g} \left( \boldsymbol{x}_{t}, \boldsymbol{u}_t \right) + \boldsymbol{w}_{t}
\end{equation}
\end{subequations}

with the state $\boldsymbol{x}_t \in \mathbb{R}^{n_x \in \mathbb{N}}$, the input $\boldsymbol{u}_t \in \mathbb{R}^{n_u \in \mathbb{N}}$, the output $\boldsymbol{y}_t \in \mathbb{R}^{n_y \in \mathbb{N}}$, the process noise $\boldsymbol{v}_{t} \in \mathbb{R}^{n_x}$, the measurement noise $\boldsymbol{w}_{t} \in \mathbb{R}^{n_y}$ and time $t \in \mathbb{Z}$. 

In our setting, only the output $\boldsymbol{y}$ is observable and the state transition function $\boldsymbol{f}(\cdot)$ and the observation function $\boldsymbol{g}(\cdot)$, as well as the distributions $\boldsymbol{\mathcal{V}}$ and $\boldsymbol{\mathcal{W}}$ of the process noise $\boldsymbol{v}$ and measurement noise $\boldsymbol{w}$ are unknown.

We assume that a dataset $\mathbb{D} = \left\{\boldsymbol{u}_{t}, \boldsymbol{y}_{t}\right\}_{t = \text{-}T:\text{-}1}$ containing the last $T \in \mathbb{N}$ measurements of the input $\boldsymbol{u}$ and output $\boldsymbol{y}$ is available.

We further assume that the structure of the model $\left\{\boldsymbol{f}_{\boldsymbol{\theta}}(\cdot), \boldsymbol{g}_{\boldsymbol{\theta}}(\cdot), \boldsymbol{\mathcal{V}}_{\boldsymbol{\theta}}, \boldsymbol{\mathcal{W}}_{\boldsymbol{\theta}}\right\}$ is known, for example through the underlying physics of the applications, and is dependent on a finite number of unknown parameters $\boldsymbol{\theta}$. In addition to that, the priors $p(\boldsymbol{\theta})$ and $p(\boldsymbol{x}_{\text{-}T})$ are available as well.

The objective is to minimize a given cost function 

\begin{equation} \label{cost function}
J_H = \sum_{t = 0}^H c(\boldsymbol{u}_t,  \boldsymbol{x}_t,  \boldsymbol{y}_t)
\end{equation}

over the horizon $H$ while satisfying the constraints 

\begin{equation} \label{constraints}
\boldsymbol{h}(\boldsymbol{u}_{0:H},  \boldsymbol{x}_{0:H},  \boldsymbol{y}_{0:H}) \leq \boldsymbol{0}
\end{equation}

with $\boldsymbol{h} \in \mathbb{R}^{n_c}$ being a vector of arbitrary deterministic function. As the states $\boldsymbol{x}_{0:H}$ are unknown to us and there are several uncertain factors in our system, the constraints are transformed into chance-constraints and since it is possible that $\boldsymbol{h}$ is impossible to satisfy for every possible $\boldsymbol{x}_{0:H}$, we also introduce a risk factor $\alpha \in [0, 1]$ that relaxes these constraints, turning them into

\begin{equation} \label{risk constraints}
P \left[ \text{max} (\boldsymbol{h}(\boldsymbol{u}_{0:H},  \boldsymbol{x}_{0:H},  \boldsymbol{y}_{0:H})) \leq 0 \right] \geq 1 - \alpha
\end{equation}

with $P$ being generally unknown.

\section{Related Work} \label{Related Work}

%From Robert's \emph{Learning-Based Optimal Control with Performance Guarantees for Unknown Systems with Latent States}\cite{Robert2024}:

The problem presented in Sec. \ref{Problem Statement} provides several challenges as the information we have available is very limited. While many methods to solve chance constraint problems exist, they often rely on samples from the distribution $P$ which is generally unknown in our problem. While we do have priors for the uncertain elements, samples drawn from this distributions do not allow as to quantify the system enough for practical applications. As such, the priors must be updated based on the input-output measurements $\mathbb{D}$ which generally results in an analytically intractable posterior distribution.

To draw samples from this distribution, methods such as particle Markov chain Monte Carlo (PMCMC) Methods \cite{Andrieu_10} can be used. This has recently been exploited for optimal control in \cite{Robert_24} , utilizing such a sampler to generate scenarios for the system and using these scenarios as a representation of the unknown distribution to formulate a deterministic optimal control problem by reformulating the chance-constraints. However, the usage of the scenarios in this paper comes with the drawback of the risk factor $\alpha$ not being part of the final optimal control problem (OCP) and the process of estimating it retroactively being quite ressource intensive.

As such, there is a need to find other methods that allow us to utilize the samples generated by PG sampler to reformulate the chance-constraints to find a distributionally robust solution without losing the risk factor in the process. 

As the difficulties with this can be traced back to the unknown distribution $P$, kernel distribution embeddings have been proposed in \cite{Adam_21} and \cite{Adam_22} to reformulate chance constrained control problems. However, these approaches work under the assumption that the states are known and does not allow for the latent states we are working with in our problem.

Another workaround that has been proposed is the use of ambiguity sets. Here, ambiguity sets are defined as a set of probability distributions that are within a certain radius under an appropriate distance function. This was used in \cite{Hota_19} with Wasserstein distance as the metric for the ambiguity set. It has however been proven rather difficult to efficiently construct a Wasserstein ambiguity set for problems. 

In contrast, the metric proposed in \cite{Yassine_22} allows for an efficient construction of an ambiguity set using a maximum mean discrepancy (MMD) metric combined with kernel approximation and can be applied to gneral non-linear and non-convex constraints.

The remainder of this paper is structured as follows. In chapter \ref{Technical Approach}, we review the methods used to solve the OCP. These methods are then tested and evaluated in chapter \ref{Evaluation} and further discussed in chapter \ref{Discussion}. Finally, the results are summarized and some concluding remarks are given in chapter \ref{Conclusion}.



%____________________________________________________